
Starting training with streaming dataset...
Note: Training on full dataset across all CSV files

============================================================
Epoch 1/600
============================================================
Processing file 1/1: action_value-00000-of-02148_data.csv
  Batch 0, Avg Loss: 0.498470, Current Loss: 0.498470
  Batch 500, Avg Loss: 0.495782, Current Loss: 0.477134
  Batch 1000, Avg Loss: 0.495924, Current Loss: 0.511910
  Batch 1500, Avg Loss: 0.495405, Current Loss: 0.551080
  Batch 2000, Avg Loss: 0.496110, Current Loss: 0.470692
  Batch 2500, Avg Loss: 0.495916, Current Loss: 0.516148
  Batch 3000, Avg Loss: 0.495574, Current Loss: 0.443222
  Batch 3500, Avg Loss: 0.495269, Current Loss: 0.503391
  Batch 4000, Avg Loss: 0.495020, Current Loss: 0.494171
  Batch 4500, Avg Loss: 0.495195, Current Loss: 0.460104
  Batch 5000, Avg Loss: 0.495119, Current Loss: 0.504754
  Batch 5500, Avg Loss: 0.494730, Current Loss: 0.549580
  Batch 6000, Avg Loss: 0.494746, Current Loss: 0.534735
  Batch 6500, Avg Loss: 0.494725, Current Loss: 0.524216
  Batch 7000, Avg Loss: 0.494772, Current Loss: 0.522172
  Batch 7500, Avg Loss: 0.494973, Current Loss: 0.503873
  Batch 8000, Avg Loss: 0.494958, Current Loss: 0.508822
  Batch 8500, Avg Loss: 0.494938, Current Loss: 0.448094
  Batch 9000, Avg Loss: 0.494845, Current Loss: 0.553497
  Batch 9500, Avg Loss: 0.494747, Current Loss: 0.498401
  Batch 10000, Avg Loss: 0.494674, Current Loss: 0.520867
  Batch 10500, Avg Loss: 0.494574, Current Loss: 0.538467
  Batch 11000, Avg Loss: 0.494563, Current Loss: 0.461211
  Batch 11500, Avg Loss: 0.494457, Current Loss: 0.525043
  Batch 12000, Avg Loss: 0.494370, Current Loss: 0.469802
  Batch 12500, Avg Loss: 0.494294, Current Loss: 0.511860
  Batch 13000, Avg Loss: 0.494236, Current Loss: 0.484993
  Batch 13500, Avg Loss: 0.494253, Current Loss: 0.474363
  Batch 14000, Avg Loss: 0.494175, Current Loss: 0.473605
  Batch 14500, Avg Loss: 0.494132, Current Loss: 0.507952
  Batch 15000, Avg Loss: 0.494165, Current Loss: 0.523278
  Batch 15500, Avg Loss: 0.494035, Current Loss: 0.463365
  Batch 16000, Avg Loss: 0.493932, Current Loss: 0.517802
  Batch 16500, Avg Loss: 0.493869, Current Loss: 0.476309
  Batch 17000, Avg Loss: 0.493903, Current Loss: 0.487638
  Batch 17500, Avg Loss: 0.493953, Current Loss: 0.454442
  Batch 18000, Avg Loss: 0.494021, Current Loss: 0.506636
  Batch 18500, Avg Loss: 0.494019, Current Loss: 0.479409
  Batch 19000, Avg Loss: 0.493986, Current Loss: 0.506845
  Batch 19500, Avg Loss: 0.493967, Current Loss: 0.528257
  Batch 20000, Avg Loss: 0.493900, Current Loss: 0.533503
  Batch 20500, Avg Loss: 0.493872, Current Loss: 0.438778
  Batch 21000, Avg Loss: 0.493858, Current Loss: 0.488094
  Batch 21500, Avg Loss: 0.493805, Current Loss: 0.502825
  Batch 22000, Avg Loss: 0.493799, Current Loss: 0.477158
  Batch 22500, Avg Loss: 0.493755, Current Loss: 0.509946
  Batch 23000, Avg Loss: 0.493655, Current Loss: 0.505371
Traceback (most recent call last):
  File "/Users/lewis/disschess/halfkp/train.py", line 483, in <module>
    main()
  File "/Users/lewis/disschess/halfkp/train.py", line 451, in main
    train_loss = train_epoch(model, train_loader, optimizer, criterion, device, is_streaming=True)
                 ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/lewis/disschess/halfkp/train.py", line 317, in train_epoch
    total_loss += loss.item()
                  ^^^^^^^^^^^
KeyboardInterrupt
